{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_recognition.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "obdLyUatornO"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frZHr_12K1be"
      },
      "source": [
        "2) Clone repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeU8H0mGC2VC"
      },
      "source": [
        "%cd '/content/drive/MyDrive/AI/AI_practise/gitclone'\r\n",
        "!ls \r\n",
        "#! git clone https://github.com/hoaquocphan/face_recognition\r\n",
        "%cd 'face_recognition'\r\n",
        "!pwd\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmpZDT88Kwa0"
      },
      "source": [
        "3) Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9dIOyg5Dem0"
      },
      "source": [
        "!ls\r\n",
        "#! pip install onnxruntime\r\n",
        "#!python3 prepare_data.py --d UTKFace\r\n",
        "#!rm -r model\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTKUubJNicP5"
      },
      "source": [
        "#!python3 train_model.py \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKqgdDQnSus8"
      },
      "source": [
        "4) Run script train model train_model.py or run command !python3 train_model.py "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sahQUvfeLSsd"
      },
      "source": [
        "4-1) Load library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5u7Pp2dS0Gr"
      },
      "source": [
        "from os import walk\r\n",
        "import os\r\n",
        "# TensorFlow and tf.keras\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "# Helper libraries\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import cv2\r\n",
        "\r\n",
        "def preprocess_image(img):\r\n",
        "    image = cv2.imread(img)\r\n",
        "    input_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n",
        "    input_img = cv2.resize(input_img, (182, 182)) \r\n",
        "    return input_img\r\n",
        "\r\n",
        "def get_label(dir,num_class):\r\n",
        "    image_name = []\r\n",
        "    labels = []\r\n",
        "    count = 0\r\n",
        "    for (dirpath, dirnames, filenames) in walk(dir):\r\n",
        "        image_name.extend(filenames)\r\n",
        "    for image in image_name:\r\n",
        "        if image.split(\"_\")[0] not in labels:\r\n",
        "            count +=1\r\n",
        "        if count > num_class:\r\n",
        "            break\r\n",
        "        labels.append(image.split(\"_\")[0])\r\n",
        "\r\n",
        "    labels = [int(numeric_string) for numeric_string in labels]\r\n",
        "    labels=np.array(labels)\r\n",
        "    return labels\r\n",
        "\r\n",
        "def get_images(dir,num_class):\r\n",
        "    image_name=[]\r\n",
        "    images =[]\r\n",
        "    image_name2=[]\r\n",
        "    count = 0\r\n",
        "    for (dirpath, dirnames, filenames) in walk(dir):\r\n",
        "        image_name.extend(filenames)\r\n",
        "    for image in image_name:\r\n",
        "        if image.split(\"_\")[0] not in image_name2:\r\n",
        "            count +=1\r\n",
        "        if count > num_class:\r\n",
        "            break\r\n",
        "        image_name2.append(image.split(\"_\")[0])\r\n",
        "        image_file = dir + \"/\" + image\r\n",
        "        image=preprocess_image(image_file)\r\n",
        "        images.append(image)\r\n",
        "    images = np.array(images)\r\n",
        "    images = images/255.0\r\n",
        "    return images\r\n",
        "\r\n",
        "\r\n",
        "def create_model(num_class):\r\n",
        "    model = tf.keras.Sequential([\r\n",
        "        tf.keras.layers.Flatten(input_shape=(182, 182)),\r\n",
        "        tf.keras.layers.Dense(640, activation='relu'),\r\n",
        "        tf.keras.layers.Dense(int(num_class)) #number of class\r\n",
        "    ])\r\n",
        "    model.compile(optimizer='adam',\r\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "              metrics=['accuracy'])\r\n",
        "    model.summary()\r\n",
        "    return model\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHQlI3FFS9ye"
      },
      "source": [
        "4-2) Processing and getting data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnCYTErMS4ts"
      },
      "source": [
        "from os import walk\r\n",
        "import os\r\n",
        "# TensorFlow and tf.keras\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "# Helper libraries\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import cv2\r\n",
        "from lib import get_label, get_images, create_model\r\n",
        "import argparse\r\n",
        "print(tf.__version__)\r\n",
        "\r\n",
        "\r\n",
        "num_class=48\r\n",
        "\r\n",
        "\r\n",
        "print(\"loading train label\")\r\n",
        "if os.path.isfile(\"train_labels.npy\"):\r\n",
        "    print(\"load file numpy\")\r\n",
        "    train_labels = np.load('train_labels.npy') \r\n",
        "else:\r\n",
        "    train_labels = get_label(\"train\",num_class)\r\n",
        "    np.save('train_labels.npy', train_labels)\r\n",
        "\r\n",
        "print(\"loading validation label\")\r\n",
        "if os.path.isfile(\"validation_labels.npy\"):\r\n",
        "    print(\"load file numpy\")\r\n",
        "    validation_labels = np.load('validation_labels.npy')\r\n",
        "else:\r\n",
        "    validation_labels = get_label(\"validation\",num_class)\r\n",
        "    np.save('validation_labels.npy', validation_labels)\r\n",
        "\r\n",
        "print(\"loading train image\")\r\n",
        "if os.path.isfile(\"train_images.npy\"):\r\n",
        "    print(\"load file numpy\")\r\n",
        "    train_images = np.load('train_images.npy')\r\n",
        "else:\r\n",
        "    train_images = get_images(\"train\",num_class)\r\n",
        "    np.save('train_images.npy', train_images)\r\n",
        "\r\n",
        "print(\"loading validation image\")\r\n",
        "if os.path.isfile(\"validation_images.npy\"):\r\n",
        "    print(\"load file numpy\")\r\n",
        "    validation_images = np.load('validation_images.npy')\r\n",
        "else:\r\n",
        "    validation_images = get_images(\"validation\",num_class)\r\n",
        "    np.save('validation_images.npy', validation_images)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-0HlsANXR8N"
      },
      "source": [
        "print(train_labels.shape)\r\n",
        "print(validation_labels.shape)\r\n",
        "print(train_images.shape)\r\n",
        "print(validation_images.shape)\r\n",
        "!ls\r\n",
        "#rm train_images.npy train_labels.npy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTiv60W6THnO"
      },
      "source": [
        "4-3) Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwfeNViJTFhW"
      },
      "source": [
        "model=create_model(num_class)\r\n",
        "\r\n",
        "\r\n",
        "checkpoint_path = \"model/cp.ckpt\"\r\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\r\n",
        "\r\n",
        "# Create a callback that saves the model's weights\r\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1)\r\n",
        "# Train model by train image \r\n",
        "print(\"training model\")\r\n",
        "model.fit(train_images, train_labels, epochs=50,validation_data=(validation_images, validation_labels), callbacks=[cp_callback])\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "test_loss, test_acc = model.evaluate(validation_images,  validation_labels, verbose=2)\r\n",
        "print(\"model, accuracy: {:5.2f}%\".format(100 * test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}